{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD4pBfiKO1p0vqVwcED4+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AzzahraFebia/Big-Data/blob/main/Hands_On_Pertemuan_3_2420506023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89f7684"
      },
      "source": [
        "# Hands-On Pertemuan 3: Data Processing dengan Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e30ce9d1"
      },
      "source": [
        "## Tujuan:\n",
        "- Memahami dan mempraktikkan data processing menggunakan Apache Spark.\n",
        "- Menggunakan Spark untuk operasi data yang efisien pada dataset besar.\n",
        "- Menerapkan teknik canggih dalam Spark untuk mengatasi kasus penggunaan nyata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd5c2f90"
      },
      "source": [
        "### 1. Pengenalan Spark DataFrames\n",
        "Spark DataFrame menyediakan struktur data yang optimal dengan operasi yang dioptimalkan untuk pemrosesan data besar, yang sangat mirip dengan DataFrame di Pandas atau di RDBMS.\n",
        "\n",
        "- **Tugas 1**: Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "986d01c7"
      },
      "outputs": [],
      "source": [
        "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000)]\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 1\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkxQysAIJJn",
        "outputId": "214ebe1a-ecdd-4ad9-cfda-1612b4c2ba9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|       James|     Sales|  3000|\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "|       Maria|   Finance|  3000|\n",
            "|       Wilio|        IT|  4500|\n",
            "|        Sean| Marketing|  4200|\n",
            "|      Alluna|        HR|  3900|\n",
            "+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fca66b73"
      },
      "source": [
        "### 2. Transformasi Dasar dengan DataFrames\n",
        "Pemrosesan data meliputi transformasi seperti filtering, selections, dan aggregations. Spark menyediakan cara efisien untuk melaksanakan operasi ini.\n",
        "\n",
        "- **Tugas 2**: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58232678"
      },
      "outputs": [],
      "source": [
        "# Contoh operasi transformasi DataFrame\n",
        "select('EmployeeName', 'Salary').show()\n",
        "filter(df['Salary'] > 3000).show()\n",
        "groupBy('Department').avg('Salary').show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPERASI FILTER\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.filter((df['Department'] == 'Sales') & (df['Salary'] > 3500)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi_Ddce6NDjX",
        "outputId": "0e4a3a69-fa4d-4d44-9712-71f7078c4778"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPERASI SELECT\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.select('EmployeeName', 'Salary').show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvxJivCDUJfC",
        "outputId": "e18fb91d-3697-4a3b-cdd0-af2936904cdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|EmployeeName|Salary|\n",
            "+------------+------+\n",
            "|       James|  3000|\n",
            "|     Michael|  4600|\n",
            "|      Robert|  4100|\n",
            "|       Maria|  3000|\n",
            "|       Wilio|  4500|\n",
            "|        Sean|  4200|\n",
            "|      Alluna|  3900|\n",
            "+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPERASI GROUPBY\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.groupBy('Department').avg('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bs1az70U492",
        "outputId": "9e3f0b24-ce87-4f9e-88ec-8ded5d2dc65e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3900.0|\n",
            "|        HR|     3900.0|\n",
            "|   Finance|     3000.0|\n",
            "| Marketing|     4200.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AGREGASI\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as FC\n",
        "\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Menggabungkan agregasi dalam satu tabel\n",
        "df.groupBy('Department').agg(\n",
        "    FC.sum('Salary').alias('Total_Gaji'),\n",
        "    FC.max('Salary').alias('Max_Gaji'),\n",
        "    FC.min('Salary').alias('Min_Gaji'),\n",
        "    FC.mean('Salary').alias('Mean_GajI'),\n",
        "    FC.count('Salary').alias('Count_Gaji')\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzEDZUzuZLjg",
        "outputId": "3863c451-8494-4184-ba36-8cc106f3e56e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+--------+--------+---------+----------+\n",
            "|Department|Total_Gaji|Max_Gaji|Min_Gaji|Mean_GajI|Count_Gaji|\n",
            "+----------+----------+--------+--------+---------+----------+\n",
            "|     Sales|     11700|    4600|    3000|   3900.0|         3|\n",
            "|        HR|      3900|    3900|    3900|   3900.0|         1|\n",
            "|   Finance|      3000|    3000|    3000|   3000.0|         1|\n",
            "| Marketing|      4200|    4200|    4200|   4200.0|         1|\n",
            "|        IT|      4500|    4500|    4500|   4500.0|         1|\n",
            "+----------+----------+--------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89763d36"
      },
      "source": [
        "### 3. Bekerja dengan Tipe Data Kompleks\n",
        "Spark mendukung tipe data yang kompleks seperti maps, arrays, dan structs yang memungkinkan operasi yang lebih kompleks pada dataset yang kompleks.\n",
        "\n",
        "- **Tugas 3**: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14701d79"
      },
      "outputs": [],
      "source": [
        "# Contoh manipulasi tipe data kompleks\n",
        "df.withColumn('SalaryBonus', df['Salary'] * 0.1).show()\n",
        "df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus']).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 3\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Menambahkan kolom SalaryBonus (0.1 / 10% dari Salary)\n",
        "df = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
        "\n",
        "# Menambahkan kolom TotalCompensation (Salary + SalaryBonus)\n",
        "df = df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus'])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3000QGc6f9KO",
        "outputId": "1894cf2d-4834-42de-e44b-75df157572e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+-----------+-----------------+\n",
            "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "|       James|     Sales|  3000|      300.0|           3300.0|\n",
            "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
            "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
            "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
            "|       Wilio|        IT|  4500|      450.0|           4950.0|\n",
            "|        Sean| Marketing|  4200|      420.0|           4620.0|\n",
            "|      Alluna|        HR|  3900|      390.0|           4290.0|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b3b58dd"
      },
      "source": [
        "### 4. Operasi Data Lanjutan\n",
        "Menggunakan Spark untuk operasi lanjutan seperti window functions, user-defined functions (UDFs), dan mengoptimalkan query.\n",
        "\n",
        "- **Tugas 4**: Implementasikan window function untuk menghitung running totals atau rangkings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "035312eb"
      },
      "outputs": [],
      "source": [
        "# Contoh menggunakan window functions\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
        "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 4\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as FC\n",
        "\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000),\n",
        "        ('Wilio', 'IT', 4500),\n",
        "        ('Sean', 'Marketing', 4200),\n",
        "        ('Alluna', 'HR', 3900)]\n",
        "\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# WindowSpec untuk membagi data sesuai departmen, dan mengurutkan sesuai salary\n",
        "windowSpec = Window.partitionBy('Department').orderBy(FC.desc('Salary'))\n",
        "\n",
        "# Menambahkan kolom ranking\n",
        "df.withColumn('Rank', FC.rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQ2WBOWixZi",
        "outputId": "72eef489-19bd-44db-bc7d-3638a325d3de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+----+\n",
            "|EmployeeName|Department|Salary|Rank|\n",
            "+------------+----------+------+----+\n",
            "|       Maria|   Finance|  3000|   1|\n",
            "|      Alluna|        HR|  3900|   1|\n",
            "|       Wilio|        IT|  4500|   1|\n",
            "|        Sean| Marketing|  4200|   1|\n",
            "|     Michael|     Sales|  4600|   1|\n",
            "|      Robert|     Sales|  4100|   2|\n",
            "|       James|     Sales|  3000|   3|\n",
            "+------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8a097ec"
      },
      "source": [
        "### 5. Kesimpulan dan Eksplorasi Lebih Lanjut\n",
        "Review apa yang telah dipelajari tentang pemrosesan data menggunakan Spark dan eksplorasi teknik lebih lanjut untuk mengoptimalkan pemrosesan data Anda.\n",
        "<br>**Tugas 5**:\n",
        "- Unduh dataset besar dari [Kaggle](https://www.kaggle.com/) atau sumber lainnya.\n",
        "- Input data csv yang telah di download, kemudian load dan simpan data ke dalam pyspark.\n",
        "- Setelah data berhasil di load menggunakan pyspark, lakukan manipulasi data untuk memperoleh informasi yang dibutuhkan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 5\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2UEEQ5aBuPLd",
        "outputId": "2ad5f9c2-9cb6-4f09-d6a6-3e612f9de229"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebf89f3a-aece-4d34-b0e1-c59ea60b6eaf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ebf89f3a-aece-4d34-b0e1-c59ea60b6eaf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving amazon.csv to amazon.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANIPULASI DATA"
      ],
      "metadata": {
        "id": "RV9vvu_602Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inisialisasi Spark\n",
        "spark = SparkSession.builder.appName(\"AmazonSalesAnalysis\").getOrCreate()\n",
        "\n",
        "# Load CSV\n",
        "df = spark.read.csv(\"amazon.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Cek struktur data\n",
        "df.printSchema()\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJPbdbdQuyOf",
        "outputId": "c2374820-d5d2-49a0-9a74-6109b7ff0a1c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- discounted_price: string (nullable = true)\n",
            " |-- actual_price: string (nullable = true)\n",
            " |-- discount_percentage: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- rating_count: string (nullable = true)\n",
            " |-- about_product: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- user_name: string (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- review_title: string (nullable = true)\n",
            " |-- review_content: string (nullable = true)\n",
            " |-- img_link: string (nullable = true)\n",
            " |-- product_link: string (nullable = true)\n",
            "\n",
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|product_id|        product_name|            category|discounted_price|actual_price|discount_percentage|rating|rating_count|        about_product|             user_id|           user_name|           review_id|        review_title|      review_content|            img_link|        product_link|\n",
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|B07JW9H4J1|Wayona Nylon Brai...|Computers&Accesso...|            ₹399|      ₹1,099|                64%|   4.2|      24,269| High Compatibilit...|AG3D6O4STAQKAY2UV...|Manav,Adarsh gupt...|R3HXWT0LRP0NMF,R2...|Satisfied,Chargin...|Looks durable Cha...|https://m.media-a...|https://www.amazo...|\n",
            "|B098NS6PVG|Ambrane Unbreakab...|Computers&Accesso...|            ₹199|        ₹349|                43%|   4.0|      43,994| Compatible with a...|AECPFYFQVRUWC3KGN...|ArdKn,Nirbhay kum...|RGIQEG07R9HS2,R1S...|A Good Braided Ca...|I ordered this ca...|https://m.media-a...|https://www.amazo...|\n",
            "|B096MSW6CT|Sounce Fast Phone...|Computers&Accesso...|            ₹199|      ₹1,899|                90%|   3.9|       7,928|【 Fast Charger& D...|AGU3BBQ2V2DDAMOAK...|Kunal,Himanshu,vi...|R3J3EQQ9TZI5ZJ,R3...|Good speed for ea...|Not quite durable...|https://m.media-a...|https://www.amazo...|\n",
            "|B08HDJ86NZ|boAt Deuce USB 30...|Computers&Accesso...|            ₹329|        ₹699|                53%|   4.2|      94,363| The boAt Deuce US...|AEWAZDZZJLQUYVOVG...|Omkar dhale,JD,HE...|R3EEUZKKK9J36I,R3...|Good product,Good...|Good product,long...|https://m.media-a...|https://www.amazo...|\n",
            "|B08CF3B7N1|Portronics Konnec...|Computers&Accesso...|            ₹154|        ₹399|                61%|   4.2|      16,905| [CHARGE & SYNC FU...|AE3Q6KSUK5P75D5HF...|rahuls6099,Swasat...|R1BP4L2HH9TFUP,R1...|As good as origin...|Bought this inste...|https://m.media-a...|https://www.amazo...|\n",
            "|B08Y1TFSP6|pTron Solero TB30...|Computers&Accesso...|            ₹149|      ₹1,000|                85%|   3.9|      24,871| Fast Charging & D...|AEQ2YMXSZWEOHK2EH...|Jayesh,Rajesh k.,...|R7S8ANNSDPR40,R3C...|It's pretty good,...|It's a good produ...|https://m.media-a...|https://www.amazo...|\n",
            "|B08WRWPM22|boAt Micro USB 55...|Computers&Accesso...|         ₹176.63|        ₹499|                65%|   4.1|      15,188| It Ensures High S...|AG7C6DAADCTRQJG2B...|Vivek kumar,Amazo...|R8E73K2KWJRDS,RSD...|Long durable.,goo...|Build quality is ...|https://m.media-a...|https://www.amazo...|\n",
            "|B08DDRGWTJ|MI Usb Type-C Cab...|Computers&Accesso...|            ₹229|        ₹299|                23%|   4.3|      30,411| 1m long Type-C US...|AHW6E5LQ2BDYOIVLA...|Pavan A H,Jayesh ...|R2X090D1YHACKR,R3...|Worth for money -...|Worth for money -...|https://m.media-a...|https://www.amazo...|\n",
            "|B008IFXQFU|TP-Link USB WiFi ...|Computers&Accesso...|            ₹499|        ₹999|                50%|   4.2|    1,79,691| USB WiFi Adapter ...|AGV3IEFANZCKECFGU...|Azhar JuMan,Aniru...|R1LW6NWSVTVZ2H,R3...|Works on linux fo...|I use this to con...|https://m.media-a...|https://www.amazo...|\n",
            "|B082LZGK39|Ambrane Unbreakab...|Computers&Accesso...|            ₹199|        ₹299|                33%|   4.0|      43,994| Universal Compati...|AECPFYFQVRUWC3KGN...|ArdKn,Nirbhay kum...|RGIQEG07R9HS2,R1S...|A Good Braided Ca...|I ordered this ca...|https://m.media-a...|https://www.amazo...|\n",
            "|B08CF3D7QR|Portronics Konnec...|Computers&Accesso...|            ₹154|        ₹339|                55%|   4.3|      13,391| [CHARGE & SYNC FU...|AGYLPKPZHVYKKZHOT...|Tanya,Anu,Akshay,...|R11MQS7WD9C3I0,R2...|Good for fast cha...|The cable is effi...|https://m.media-a...|https://www.amazo...|\n",
            "|B0789LZTCJ|boAt Rugged v3 Ex...|Computers&Accesso...|            ₹299|        ₹799|                63%|   4.2|      94,363| The boAt rugged c...|AEWAZDZZJLQUYVOVG...|Omkar dhale,JD,HE...|R3EEUZKKK9J36I,R3...|Good product,Good...|Good product,long...|https://m.media-a...|https://www.amazo...|\n",
            "|B07KSMBL2H|AmazonBasics Flex...|Electronics|HomeT...|            ₹219|        ₹700|                69%|   4.4|    4,26,973| Flexible, lightwe...|AEYJ5I6JZZPOJB6MG...|Rishav Gossain,Sh...|R1FKOKZ3HHKJBZ,R2...|It's quite good a...|I am using it for...|https://m.media-a...|https://www.amazo...|\n",
            "|B085DTN6R2|Portronics Konnec...|Computers&Accesso...|            ₹350|        ₹899|                61%|   4.2|       2,262| [20W PD FAST CHAR...|AGUAYQHARAKR2VZTR...|Priya,Mansi,Plaba...|R1QETDIPRCX4S0,RA...|Works,Nice Produc...|Definitely isn’t ...|https://m.media-a...|https://www.amazo...|\n",
            "|B09KLVMZ3B|Portronics Konnec...|Computers&Accesso...|            ₹159|        ₹399|                60%|   4.1|       4,768| [CHARGE & SYNC FU...|AF2XXVO7JUBUVAOBT...|Deepaak Singh,siv...|R20XIOU25HEX80,R2...|Great but,Worked ...|Loosing charging ...|https://m.media-a...|https://www.amazo...|\n",
            "|B083342NKJ|MI Braided USB Ty...|Computers&Accesso...|            ₹349|        ₹399|                13%|   4.4|      18,757| 1M Long Cable. Us...|AGSGSRTEZBQY64WO2...|Birendra ku Dash,...|R2JPQNKCOE10UK,RQ...|Good product,usin...|I like it 👍👍,Be...|https://m.media-a...|https://www.amazo...|\n",
            "|B0B6F7LX4C|MI 80 cm (32 inch...|Electronics|HomeT...|         ₹13,999|     ₹24,999|                44%|   4.2|      32,840| Note : The brands...|AHEVOQADJSSRX7DS3...|Manoj maddheshiya...|R13UTIA6KOF6QV,R2...|It is the best tv...|Pros- xiomi 5a is...|https://m.media-a...|https://www.amazo...|\n",
            "|B082LSVT4B|Ambrane Unbreakab...|Computers&Accesso...|            ₹249|        ₹399|                38%|   4.0|      43,994| Compatible with a...|AECPFYFQVRUWC3KGN...|ArdKn,Nirbhay kum...|RGIQEG07R9HS2,R1S...|A Good Braided Ca...|I ordered this ca...|https://m.media-a...|https://www.amazo...|\n",
            "|B08WRBG3XW|boAt Type C A325 ...|Computers&Accesso...|            ₹199|        ₹499|                60%|   4.1|      13,045| Type C A 325 Cabl...|AFB5KJR4Q5FICAHBO...|Rohan Narkar,JAGW...|R2BP8Y5OJXKJLF,R2...|Good for charging...|Check for offera ...|https://m.media-a...|https://www.amazo...|\n",
            "|B08DPLCM6T|LG 80 cm (32 inch...|Electronics|HomeT...|         ₹13,490|     ₹21,990|                39%|   4.3|      11,976| Resolution: HD Re...|AHBNKB74LGTYUOKPA...|NIRMAL.N,Manoj ku...|R2PNR69G0BQG2F,R3...|Sound quality,Ver...|LG was always Goo...|https://m.media-a...|https://www.amazo...|\n",
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SELECT KOLOM\n",
        "\n",
        "df.select('product_name','category','discounted_price','rating').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkaSQqNjxguk",
        "outputId": "ab209e42-1e00-4dad-8028-91d2bc8143a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------------+------+\n",
            "|        product_name|            category|discounted_price|rating|\n",
            "+--------------------+--------------------+----------------+------+\n",
            "|Wayona Nylon Brai...|Computers&Accesso...|            ₹399|   4.2|\n",
            "|Ambrane Unbreakab...|Computers&Accesso...|            ₹199|   4.0|\n",
            "|Sounce Fast Phone...|Computers&Accesso...|            ₹199|   3.9|\n",
            "|boAt Deuce USB 30...|Computers&Accesso...|            ₹329|   4.2|\n",
            "|Portronics Konnec...|Computers&Accesso...|            ₹154|   4.2|\n",
            "|pTron Solero TB30...|Computers&Accesso...|            ₹149|   3.9|\n",
            "|boAt Micro USB 55...|Computers&Accesso...|         ₹176.63|   4.1|\n",
            "|MI Usb Type-C Cab...|Computers&Accesso...|            ₹229|   4.3|\n",
            "|TP-Link USB WiFi ...|Computers&Accesso...|            ₹499|   4.2|\n",
            "|Ambrane Unbreakab...|Computers&Accesso...|            ₹199|   4.0|\n",
            "|Portronics Konnec...|Computers&Accesso...|            ₹154|   4.3|\n",
            "|boAt Rugged v3 Ex...|Computers&Accesso...|            ₹299|   4.2|\n",
            "|AmazonBasics Flex...|Electronics|HomeT...|            ₹219|   4.4|\n",
            "|Portronics Konnec...|Computers&Accesso...|            ₹350|   4.2|\n",
            "|Portronics Konnec...|Computers&Accesso...|            ₹159|   4.1|\n",
            "|MI Braided USB Ty...|Computers&Accesso...|            ₹349|   4.4|\n",
            "|MI 80 cm (32 inch...|Electronics|HomeT...|         ₹13,999|   4.2|\n",
            "|Ambrane Unbreakab...|Computers&Accesso...|            ₹249|   4.0|\n",
            "|boAt Type C A325 ...|Computers&Accesso...|            ₹199|   4.1|\n",
            "|LG 80 cm (32 inch...|Electronics|HomeT...|         ₹13,490|   4.3|\n",
            "+--------------------+--------------------+----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FILTER PRODUK\n",
        "\n",
        "df.filter(df['rating'] > 4.8).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us9cLHfh2Hv0",
        "outputId": "bbb18c24-5d79-418f-cf3e-2b9f42013359"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|product_id|        product_name|            category|discounted_price|actual_price|discount_percentage|rating|rating_count|       about_product|             user_id|           user_name|           review_id|        review_title|      review_content|            img_link|        product_link|\n",
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|B0BP7XLX48|Syncwire LTG to U...|Computers&Accesso...|            ₹399|      ₹1,999|                80%|   5.0|           5|This sturdy and d...|AF7EOXYL5K36BDP6P...|Amazon Customer,k...|R1L2JNO4Y3BHYF,R2...|Good,Superb quali...|Product is good i...|https://m.media-a...|https://www.amazo...|\n",
            "|B0BQRJ3C47|REDTECH USB-C to ...|Computers&Accesso...|            ₹249|        ₹999|                75%|   5.0|        NULL|💎[The Fastest Ch...|AGJC5O5H5BBXWUV7W...|         Abdul Gafur|       RQXD5SAMMPC6L|     Awesome Product|Quick delivery.Aw...|https://m.media-a...|https://www.amazo...|\n",
            "|B09ZHCJDP1|Amazon Basics Wir...|Computers&Accesso...|            ₹499|      ₹1,000|                50%|   5.0|          23|Reliable wireless...|AFLLEPVLIAH2DFSHA...|Rambeer kumar,Ram...|R76XPXMKXLWKH,R23...|Very responsive a...|I really like thi...|https://m.media-a...|https://www.amazo...|\n",
            "+----------+--------------------+--------------------+----------------+------------+-------------------+------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MENGHITUNG JUMLAH DATA\n",
        "\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCLP3zsN7pto",
        "outputId": "f01dd678-39af-4509-e16d-d9ad0b61b3d0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1465"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MEMBERSIHKAN SIMBOL MATA UANG DAN PERSEN\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace, col\n",
        "\n",
        "df = df.withColumn(\"discounted_price\",\n",
        "                   regexp_replace(\"discounted_price\", \"[^0-9.]\", \"\").cast(\"float\"))\n",
        "\n",
        "df = df.withColumn(\"rating\",\n",
        "                   regexp_replace(\"rating\", \"[^0-9.]\", \"\").cast(\"float\"))\n"
      ],
      "metadata": {
        "id": "T2IeZZxt-rqd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RINGKASAN DATA PER KATEGORI\n",
        "\n",
        "from pyspark.sql import functions as FC\n",
        "df.groupBy(\"category\").agg(\n",
        "    FC.avg(\"discounted_price\").alias(\"avg_discounted_price\"),\n",
        "    FC.count(\"*\").alias(\"total_products\"),\n",
        "    FC.max(\"rating\").alias(\"max_rating\"),\n",
        "    FC.min(\"rating\").alias(\"min_rating\")\n",
        ").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2KPVBjz1c4Q",
        "outputId": "e5af0bd5-f1dc-463f-cc45-ce954f2b06c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------+----------+----------+\n",
            "|            category|avg_discounted_price|total_products|max_rating|min_rating|\n",
            "+--------------------+--------------------+--------------+----------+----------+\n",
            "|           reminders|                NULL|             1|      90.0|      90.0|\n",
            "|Computers&Accesso...|               199.0|             1|       4.1|       4.1|\n",
            "|OfficeProducts|Of...|              141.25|             4|       4.5|       4.2|\n",
            "|OfficeProducts|Of...|  227.14285714285714|             7|       4.5|       4.1|\n",
            "|Electronics|Camer...|               299.0|             1|       3.8|       3.8|\n",
            "|Computers&Accesso...|               549.0|             1|       4.3|       4.3|\n",
            "|      TWS Connection|                NULL|             3|    3999.0|    3999.0|\n",
            "|     123 Sports Mode|                 8.0|             1|      NULL|      NULL|\n",
            "|Computers&Accesso...|               558.0|             5|       4.5|       4.0|\n",
            "|Computers&Accesso...|               749.0|             2|       4.1|       4.0|\n",
            "+--------------------+--------------------+--------------+----------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}